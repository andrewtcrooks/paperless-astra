# ğŸš€ MCP Rules for Paperless-Astra

This file contains the **Model Context Protocol (MCP) guidelines** for the **Paperless-Astra project**.

---

## ğŸ“Œ Project Overview

**Paperless-Astra** is a **fork of Paperless-ngx** that integrates **ChromaDB vector search** for **enhanced document search functionality**. It also introduces **dynamic LLM switching**, allowing users to connect to **local models (LM Studio)** or **cloud-based models (Claude, OpenAI, etc.)**.

This project introduces:
- **Vector search using ChromaDB** to improve **search accuracy**.
- **Document embeddings with Sentence Transformers** to create **high-quality vector representations**.
- **Automatic embedding generation** whenever a document is saved.
- **A new vector similarity search API endpoint** for querying documents.
- **Flexible AI model switching** for local (LM Studio) or cloud-based LLMs.

---

## ğŸ“Œ Key Components

### 1ï¸âƒ£ Multi-LLM Support (Local & Cloud)
- Connects to **LM Studio for Local LLM Models**.
- Supports **OpenAI, Claude, Mistral, etc., via API**.
- Allows users to **configure API endpoints and keys** manually.

### 2ï¸âƒ£ Intelligent Model Switching (Task-Based)
- **Selects the best model** based on the task type:
  - **Tagging (Metadata Extraction & Summarization)** â†’ Uses Claude, GPT-4, or a local LM Studio model.
  - **OCR with Vision (Processing Images, PDFs)** â†’ Uses a Vision LLM (e.g., LLaVA, GPT-4V, etc.).
  - **Reasoning (Motion Drafting, Legal Inferences)** â†’ Uses the most powerful model available.
- **Optimizes model switching** by:
  - **Batching similar tasks** to complete them before switching.
  - **Keeping a single model loaded** for as long as possible before switching.

### 3ï¸âƒ£ LM Studio Model Management
- Knows which models are available in LM Studio.
- Automatically loads/unloads models as needed.
- Users define which models specialize in which tasks.

---

## ğŸ“Œ Development Guidelines

### 1ï¸âƒ£ Code Style
- Follow **PEP 8** guidelines for Python code.
- Use **type hints (`def func(name: str) -> dict`)** for all new functions.
- **Document every function & class** with clear docstrings.
- Keep functions **single-purpose and modular** for maintainability.

### 2ï¸âƒ£ Testing
- Write **unit tests** for all new functionality.
- Ensure **edge cases** are tested, particularly for **vector searches**.
- Follow existing test patterns in **`tests/`**.

### 3ï¸âƒ£ Documentation
- Update **API docs** whenever new endpoints are added.
- Document **config options** (e.g., enabling/disabling vector search).
- Provide **code examples** for **API usage** and **configuration settings**.

### 4ï¸âƒ£ Version Control
- Use **descriptive commit messages** (`feat: added vector search API`).
- Develop **new features in branches** before merging into `main`.
- Submit **Pull Requests (PRs) for review** before merging changes.

---

## ğŸ“Œ Project Structure

src/
  paperless_astra/ # Core application
    â”œâ”€â”€ init.py # Package initialization 
    â”œâ”€â”€ vector_search/ # Vector search module 
    â”‚ â”œâ”€â”€ apps.py # Django app configuration 
    â”‚ â”œâ”€â”€ chroma_client.py # ChromaDB singleton client 
    â”‚ â”œâ”€â”€ embedding.py # Document embedding logic 
    â”‚ â”œâ”€â”€ signals.py # Auto-generate embeddings on document save 
    â”‚ â”œâ”€â”€ urls.py # URL routing for vector search 
    â”‚ â”œâ”€â”€ views.py # API endpoints for searching 
    â”‚ â””â”€â”€ serializers.py # Data serialization for search results 
    â”œâ”€â”€ mcp_server/ # MCP API for external AI models 
    â”‚ â”œâ”€â”€ models.py # MCP data structures 
    â”‚ â”œâ”€â”€ endpoints.py # MCP request handling 
    â”‚ â”œâ”€â”€ schema.py # MCP API schema definition 
    â”‚ â”œâ”€â”€ auth.py # Optional authentication for AI access 
    â”œâ”€â”€ llm_router.py # Handles intelligent LLM switching 
    â”œâ”€â”€ lm_studio_manager.py # Manages LM Studio model loading/unloading



---

## ğŸ“Œ Configuration Options

Paperless-Astra uses environment variables and a configuration file to control settings:

### **Environment Variables**
| **Variable** | **Description** | **Default** |
|-------------|----------------|------------|
| `PAPERLESS_VECTOR_SEARCH_ENABLED` | Enables/disables ChromaDB vector search | `true` |
| `PAPERLESS_CHROMA_DB_DIR` | ChromaDB storage location | `data/chroma_db` |
| `PAPERLESS_MCP_API_KEY` | API key for external LLM access | _None_ (optional) |

### **LLM Configuration File (`llm_config.json`)**
```json
{
  "default": "claude",
  "llm_backends": {
    "claude": {
      "type": "cloud",
      "url": "https://api.anthropic.com/v1/messages",
      "api_key": "your_claude_api_key"
    },
    "openai": {
      "type": "cloud",
      "url": "https://api.openai.com/v1/chat/completions",
      "api_key": "your_openai_api_key"
    },
    "local_lm_studio": {
      "type": "local",
      "lm_studio_path": "/path/to/lmstudio/models/",
      "model_names": {
        "tagging": "mistral-7b",
        "vision": "llava-13b",
        "reasoning": "gpt4all-13b"
      }
    }
  }
}

ğŸ“Œ API Endpoints

1ï¸âƒ£ Vector Search API
GET /api/vector_search/search/
Queries documents using semantic similarity search via ChromaDB.

2ï¸âƒ£ MCP API for LLM Integration
POST /api/mcp/query/
Allows external AI models to retrieve and analyze case data.

3ï¸âƒ£ LM Studio Model Switching
POST /api/llm/switch_model/
Loads/unloads the best model for the current task.